#  Working group for IDEAL special semester on the foundations of deep learning

This is the webpage for the working group lead by Edgar Dobriban at the IDEAL [special semester on the foundations of deep learning](https://www.ideal.northwestern.edu/special-quarters/fall-2020/).

## Tentative topic: 

Robustness (mainly theory of adversarial robustness).

## Notes: 

What causes adversarial examples? An overview of theoretical explanations, by Edgar Dobriban (work in progress)

## Papers:

[Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples](https://arxiv.org/abs/1802.00420)

[Certified Adversarial Robustness via Randomized Smoothing](https://arxiv.org/abs/1902.02918)

[On Evaluating Adversarial Robustness](https://arxiv.org/abs/1902.06705)

[VC Classes are Adversarially Robustly Learnable, but Only Improperly](https://arxiv.org/abs/1902.04217)

[Adversarial Examples Are Not Bugs, They Are Features](https://arxiv.org/abs/1905.02175)

## Other materials: 

See section 6.1 of [my lecture notes](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Lecture%20Notes/stat_991.pdf) for a collection of materials.
