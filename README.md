#  Working group for IDEAL special semester on the foundations of deep learning

This is the webpage for the working group lead by Edgar Dobriban at the IDEAL [special semester on the foundations of deep learning](https://www.ideal.northwestern.edu/special-quarters/fall-2020/).

## Tentative topic: 

Robustness (mainly theory of adversarial robustness).

## Notes: 

What causes adversarial examples? An overview of theoretical explanations, by Edgar Dobriban (work in progress)

## Papers:

### Theoretical and semi-theoretical studies

[Adversarial Spheres](https://arxiv.org/abs/1801.02774)

[Overfitting or perfect fitting? risk bounds for classification and regression rules that interpolate (https://arxiv.org/abs/1806.05161)

[Robustness May Be at Odds with Accuracy](https://arxiv.org/abs/1805.12152)

[Adversarial Examples Are Not Bugs, They Are Features](https://arxiv.org/abs/1905.02175)

[Adversarial Training Can Hurt Generalization](https://arxiv.org/abs/1906.06032)

[Provable tradeoffs in adversarially robust classification](https://arxiv.org/abs/2006.05161)

### General reading
[Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples](https://arxiv.org/abs/1802.00420)

[Certified Adversarial Robustness via Randomized Smoothing](https://arxiv.org/abs/1902.02918)

[On Evaluating Adversarial Robustness](https://arxiv.org/abs/1902.06705)

[VC Classes are Adversarially Robustly Learnable, but Only Improperly](https://arxiv.org/abs/1902.04217)


## Other materials: 

See section 6.1 of [my lecture notes](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Lecture%20Notes/stat_991.pdf) for a collection of materials.
